{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ohoud-Almutairi/YOLOv8-KITTI-Object-Detection/blob/main/Autonomous_Driving_Object_Detection2_YoloV8_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Autonomous Driving Object Detection Using Convolutional Neural Networks (CNNs)"
      ],
      "metadata": {
        "id": "4AlC8zNO3L3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package from PyPI\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "rJ8EYk1VbNMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# Function to download and extract a dataset using requests\n",
        "def download_and_extract(url, extract_to):\n",
        "    # Get the filename from the URL\n",
        "    zip_file_name = os.path.basename(url)\n",
        "    zip_file_path = os.path.join(extract_to, zip_file_name)\n",
        "\n",
        "    # Download the file using requests with streaming to handle large files\n",
        "    print(f\"Downloading {zip_file_name}...\")\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()  # Raise an exception for bad responses\n",
        "        with open(zip_file_path, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    print(f\"Download complete.\")\n",
        "\n",
        "    # Extract the downloaded zip file\n",
        "    print(f\"Extracting {zip_file_name}...\")\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f'Dataset downloaded and extracted to {extract_to}')\n",
        "\n",
        "    # Delete the ZIP file after extraction\n",
        "    os.remove(zip_file_path)\n",
        "    print(f'Deleted the ZIP file: {zip_file_path}')\n",
        "\n",
        "# URLs for KITTI images and labels\n",
        "kitti_image_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_image_2.zip'\n",
        "kitti_label_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/data_object_label_2.zip'\n",
        "extract_directory = './kitti_dataset'  # Specify your extraction directory\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(extract_directory, exist_ok=True)\n",
        "\n",
        "# Download and extract images and labels\n",
        "download_and_extract(kitti_image_url, extract_directory)\n",
        "download_and_extract(kitti_label_url, extract_directory)"
      ],
      "metadata": {
        "id": "DTRZbLAhcyuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Set up paths for label and image directories, and classes file\n",
        "label_dir = Path('/content/kitti_dataset/training/label_2')\n",
        "image_2_dir = Path('/content/kitti_dataset/training/image_2')\n",
        "use_dont_care = False  # Set to True to include 'DontCare' labels\n",
        "classes_path = Path('classes.json')  # Ensure this file is available\n",
        "\n",
        "# Define and create the output labels directory\n",
        "OUT_LABELS_DIR = Path(\"/content/working/labels\")\n",
        "OUT_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create a 'working' directory if needed\n",
        "working_dir = Path('/content/working')\n",
        "working_dir.mkdir(exist_ok=True)\n"
      ],
      "metadata": {
        "id": "NIVZoqlF4obj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "preprocess the KITTI dataset labels"
      ],
      "metadata": {
        "id": "6LThZ6bp4Mom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "from PIL import Image\n",
        "\n",
        "# Class labels\n",
        "KEY_PEDESTRIAN = \"Pedestrian\"\n",
        "KEY_CYCLIST = \"Cyclist\"\n",
        "KEY_CAR = \"Car\"\n",
        "KEY_VAN = \"Van\"\n",
        "KEY_MISC = \"Misc\"\n",
        "KEY_TRUCK = \"Truck\"\n",
        "KEY_PERSON_SITTING = \"Person_sitting\"\n",
        "KEY_TRAM = \"Tram\"\n",
        "KEY_DONT_CARE = \"DontCare\"\n",
        "\n",
        "\n",
        "# Class number mapping\n",
        "CLAZZ_NUMBERS = {\n",
        "    KEY_CAR: 0,\n",
        "    KEY_PEDESTRIAN: 1,\n",
        "    KEY_VAN: 2,\n",
        "    KEY_CYCLIST: 3,\n",
        "    KEY_TRUCK: 4,\n",
        "    KEY_MISC: 5,\n",
        "    KEY_TRAM: 6,\n",
        "    KEY_PERSON_SITTING: 7,\n",
        "    KEY_DONT_CARE: 8\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def getSampleId(path):\n",
        "    basename = os.path.basename(path)\n",
        "    return os.path.splitext(basename)[0]\n",
        "\n",
        "def resolveClazzNumberOrNone(clazz, use_dont_care):\n",
        "\n",
        "    if use_dont_care and clazz == KEY_DONT_CARE:\n",
        "        return CLAZZ_NUMBERS[clazz]\n",
        "    elif clazz != KEY_DONT_CARE:\n",
        "        return CLAZZ_NUMBERS[clazz]\n",
        "    return None\n",
        "\n",
        "def convertToYoloBBox(bbox, size):\n",
        "    dw = 1. / size[0]\n",
        "    dh = 1. / size[1]\n",
        "    x = (bbox[0] + bbox[1]) / 2.0\n",
        "    y = (bbox[2] + bbox[3]) / 2.0\n",
        "    w = bbox[1] - bbox[0]\n",
        "    h = bbox[3] - bbox[2]\n",
        "    x = x * dw\n",
        "    w = w * dw\n",
        "    y = y * dh\n",
        "    h = h * dh\n",
        "    return (x, y, w, h)\n",
        "\n",
        "def readRealImageSize(img_path):\n",
        "    return Image.open(img_path).size\n",
        "\n",
        "def parseSample(lbl_path, img_path, use_dont_care):\n",
        "    with open(lbl_path) as csv_file:\n",
        "        reader = csv.DictReader(csv_file, fieldnames=[\"type\", \"truncated\", \"occluded\", \"alpha\", \"bbox2_left\", \"bbox2_top\", \"bbox2_right\", \"bbox2_bottom\", \"bbox3_height\", \"bbox3_width\", \"bbox3_length\", \"bbox3_x\", \"bbox3_y\", \"bbox3_z\", \"bbox3_yaw\", \"score\"], delimiter=\" \")\n",
        "        yolo_labels = []\n",
        "        for row in reader:\n",
        "            clazz_number = resolveClazzNumberOrNone(row[\"type\"], use_dont_care)\n",
        "            if clazz_number is not None:\n",
        "                size = readRealImageSize(img_path)\n",
        "                bbox = (\n",
        "                    float(row[\"bbox2_left\"]),\n",
        "                    float(row[\"bbox2_right\"]),\n",
        "                    float(row[\"bbox2_top\"]),\n",
        "                    float(row[\"bbox2_bottom\"])\n",
        "                )\n",
        "                yolo_bbox = convertToYoloBBox(bbox, size)\n",
        "                yolo_label = (clazz_number,) + yolo_bbox\n",
        "                yolo_labels.append(yolo_label)\n",
        "    return yolo_labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Generating YOLO labels...\")\n",
        "sample_img_paths = []\n",
        "for dir_path, sub_dirs, files in os.walk(label_dir):\n",
        "    for file_name in files:\n",
        "        if file_name.endswith(\".txt\"):\n",
        "            lbl_path = os.path.join(dir_path, file_name)\n",
        "            sample_id = getSampleId(lbl_path)\n",
        "            img_path = os.path.join(image_2_dir, \"{}.png\".format(sample_id))\n",
        "            sample_img_paths.append(img_path)\n",
        "            yolo_labels = parseSample(lbl_path, img_path, use_dont_care)\n",
        "            with open(os.path.join(str(OUT_LABELS_DIR), \"{}.txt\".format(sample_id)), \"w\") as yolo_label_file:\n",
        "                for lbl in yolo_labels:\n",
        "                    yolo_label_file.write(\"{} {} {} {} {}\\n\".format(*lbl))\n",
        "\n",
        "print(\"YOLO labels generation complete!\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "09tvfWSdu7fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Prepare the Dataset\n",
        "Prepare the images and labels for training."
      ],
      "metadata": {
        "id": "R-hzPeym6j84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Class mapping\n",
        "classes = {\n",
        "    \"Car\": 0,\n",
        "    \"Pedestrian\": 1,\n",
        "    \"Van\": 2,\n",
        "    \"Cyclist\": 3,\n",
        "    \"Truck\": 4,\n",
        "    \"Misc\": 5,\n",
        "    \"Tram\": 6,\n",
        "    \"Person_sitting\": 7\n",
        "}\n",
        "\n",
        "# Save classes to a JSON file\n",
        "classes_path = 'classes.json'\n",
        "with open(classes_path, 'w') as f:\n",
        "    json.dump(classes, f, indent=4)\n",
        "\n",
        "# Prepare images and labels\n",
        "ims = sorted(list(image_2_dir.glob('*')))\n",
        "labels = sorted(list(OUT_LABELS_DIR.glob('*')))\n",
        "pairs = list(zip(ims, labels))\n",
        "\n",
        "data_size = len(pairs)\n",
        "# Check if the dataset is large enough\n",
        "if data_size > 0:\n",
        "\n",
        "    train, test = train_test_split(pairs, test_size=0.1, shuffle=True)\n",
        "    # Create train and valid directories\n",
        "    train_path = Path('/content/working/train').resolve()\n",
        "    valid_path = Path('/content/working/valid').resolve()\n",
        "\n",
        "    # Delete the directories if they exist\n",
        "    if train_path.exists() and train_path.is_dir():\n",
        "        shutil.rmtree(train_path)\n",
        "\n",
        "    if valid_path.exists() and valid_path.is_dir():\n",
        "        shutil.rmtree(valid_path)\n",
        "\n",
        "    train_path.mkdir(exist_ok=True)\n",
        "    valid_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Copy training data\n",
        "    for t_img, t_lb in tqdm(train):\n",
        "        shutil.copy(t_img, train_path / t_img.name)\n",
        "        shutil.copy(t_lb, train_path / t_lb.name)\n",
        "\n",
        "    # Copy validation data\n",
        "    for t_img, t_lb in tqdm(test):\n",
        "        shutil.copy(t_img, valid_path / t_img.name)\n",
        "        shutil.copy(t_lb, valid_path / t_lb.name)\n",
        "\n",
        "print(\"\\nData preparation complete!\")\n"
      ],
      "metadata": {
        "id": "it5-1Rym_1nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Create the YAML Configuration File\n",
        "You need a YAML file to define the dataset structure."
      ],
      "metadata": {
        "id": "oWiVVIB56p3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_file = 'names:\\n'\n",
        "yaml_file += '\\n'.join(f'- {c}' for c in classes)\n",
        "yaml_file += f'\\nnc: {len(classes)}'\n",
        "yaml_file += f'\\ntrain: {str(train_path)}\\nval: {str(valid_path)}'\n",
        "with open('/content/working/kitti.yaml', 'w') as f:\n",
        "    f.write(yaml_file)"
      ],
      "metadata": {
        "id": "4x8pOgrSAk39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Train the YOLOv8 Model\n",
        "Now you can set up and train the YOLOv8 model."
      ],
      "metadata": {
        "id": "stbqRBd66tMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "model = YOLO('yolov8n.yaml')\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "\n",
        "# Train the model\n",
        "train_results = model.train(\n",
        "    data='/content/working/kitti.yaml',  # Ensure the correct path to your YAML file\n",
        "    epochs=15,\n",
        "    batch=100,\n",
        "    patience=3,\n",
        "    mixup=0.1,\n",
        "    project='yolov8n-kitti',  # Name of the project folder for saving results\n",
        "\n",
        ")\n"
      ],
      "metadata": {
        "id": "6DHhnhyuA62K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Validate and Visualize Results\n",
        "You can validate the model and visualize the training results."
      ],
      "metadata": {
        "id": "_-IpymQ26yiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate the model\n",
        "valid_results = model.val()\n"
      ],
      "metadata": {
        "id": "gC9Xscbq6w83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training results\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.imshow(Image.open('/content/yolov8n-kitti/train/results.png'))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "WTpCU55ScrKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,20))\n",
        "plt.imshow(Image.open('/content/yolov8n-kitti/train2/confusion_matrix.png'))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x7fDMerQEq3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Make Predictions\n",
        "You can make predictions on a set of images."
      ],
      "metadata": {
        "id": "PwGFNUlQ7YDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "preds = model.predict([test[idx][0] for idx in np.random.randint(0,len(test),(20,))],save=True)\n"
      ],
      "metadata": {
        "id": "GFMz_PI-7d1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = list(Path('yolov8n-kitti/train3').glob('*'))\n",
        "\n",
        "# Function to plot images\n",
        "def plot_images(images):\n",
        "    num_images = len(images)\n",
        "    rows = num_images\n",
        "    cols = 1\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(15, 80))\n",
        "    for ax in axes.flat:\n",
        "        ax.axis('off')\n",
        "    for i, img_path in enumerate(images):\n",
        "        img = Image.open(img_path)\n",
        "        axes[i].imshow(img)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot predicted images\n",
        "plot_images(preds)"
      ],
      "metadata": {
        "id": "AHOK4VlfDb0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of calculating accuracy\n",
        "def calculate_accuracy(predictions, ground_truth):\n",
        "    correct = 0\n",
        "    total = len(predictions)\n",
        "\n",
        "    for pred, true_label in zip(predictions, ground_truth):\n",
        "        if pred == true_label:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Example ground truth labels and model predictions\n",
        "ground_truth_labels = [0, 1, 1, 0, 1]\n",
        "model_predictions = [0, 1, 0, 0, 1]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = calculate_accuracy(model_predictions, ground_truth_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "N_bwGkxqv_Iw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}